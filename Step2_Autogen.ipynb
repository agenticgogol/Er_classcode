{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb3c8a5",
   "metadata": {},
   "source": [
    "### Autogen uses async functionality for real time agent interactions\n",
    "- If Agent calls an API , we can keep it in background and carry on with other tasks while it waits for response\n",
    "- Synchronous -1 by 1 sequential execution\n",
    "- async - co routine execution (multiple task execution simultaneously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfbe9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brewing Coffee\n",
      "Coffee Ready\n",
      "Toasting Bread\n",
      "bread Ready\n",
      "Time : 5.01 minutes\n"
     ]
    }
   ],
   "source": [
    "# Sync process\n",
    "import time\n",
    "def brew_coffee():\n",
    "    print(\"Brewing Coffee\")\n",
    "    time.sleep(3) # 3 Minutes\n",
    "    print(\"Coffee Ready\")\n",
    "\n",
    "def toast_bread():\n",
    "    print(\"Toasting Bread\")\n",
    "    time.sleep(2) # 2 Minutes\n",
    "    print(\"bread Ready\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "coffee = brew_coffee()\n",
    "# time.sleep(2)\n",
    "bread = toast_bread()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(f\"Time : {end - start:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cbfb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Brewing Coffee\n",
      "Start Toasting bread\n",
      "Bread Ready\n",
      "Coffee Ready\n",
      "Time : 3.00 minutes\n"
     ]
    }
   ],
   "source": [
    "# Async process\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def brew_coffee():\n",
    "    print(\"Starting Brewing Coffee\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(\"Coffee Ready\")\n",
    "\n",
    "async def toast_bread():\n",
    "    print(\"Start Toasting bread\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Bread Ready\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "coffee = brew_coffee()\n",
    "bread = toast_bread()\n",
    "\n",
    "results = await asyncio.gather(coffee,bread)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time : {end - start:.2f} minutes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dece3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Brewing Coffee\n",
      "Start Toasting bread\n",
      "Bread Ready\n",
      "Coffee Ready\n",
      "Time : 3.01 minutes\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def brew_coffee_async():\n",
    "    print(\"Starting Brewing Coffee\")\n",
    "    await asyncio.sleep(3)\n",
    "    print(\"Coffee Ready\")\n",
    "\n",
    "async def toast_bread_async():\n",
    "    print(\"Start Toasting bread\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Bread Ready\")\n",
    "\n",
    "async def main_individual():\n",
    "    start = time.time()\n",
    "    coffee_task = asyncio.create_task(brew_coffee_async())\n",
    "    bread_task = asyncio.create_task(toast_bread_async())\n",
    "\n",
    "    coffee = await coffee_task\n",
    "    bagel = await bread_task\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Time : {end - start:.2f} minutes\")\n",
    "\n",
    "\n",
    "await (main_individual())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74129d69",
   "metadata": {},
   "source": [
    "# Now more on AgentChat ( What we already saw)\n",
    "- Agentchat gives us a async powered way to handle agent conversation\n",
    "- It helps us to define agents and enable them to chat , collaborate and solve tasks\n",
    "- event driven i.e response to task as they come\n",
    "- features are - customization with prompts we can do , we can connect it to LLMs \n",
    "- This is a high level API makes development is very easy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d28926",
   "metadata": {},
   "source": [
    "# Customizing the Agents and prompt engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f06864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the future of international relations involves a good deal of uncertainty and speculation. However, a few trends hint at the possible trajectory of the relationship between India and the United States. \n",
      "\n",
      "1. Shared Democratic Values: As two of the world's largest democracies, the US and India share many values, such as the importance of a democratic government and the rule of law. These shared values remain a cornerstone in their partnership.\n",
      "\n",
      "2. Strategic Partner: India's location makes it a key strategic partner for the US, especially in relation to China. US regards India as an important partner in the Indo-Pacific region. If tensions between the US and China continue to escalate, the strategic significance of India will likely increase.\n",
      "\n",
      "3. Trade Relations: Economic and trade relations between the two countries have been a friction point. Both sides have expressed interest in a trade deal, but disagreements over specific terms have hampered progress. The future relationship will be determined, in part, by whether they can find a mutually agreeable solution to these trade disputes.\n",
      "\n",
      "4. Climate Change Cooperation: US return to the Paris Agreement under President Biden could lead to increased cooperation with India on issues like climate change, clean energy and green technology.\n",
      "\n",
      "5. Technology and Innovation: The two countries continue to collaborate in the field of technology and innovation. Future ties could be determined by cooperation in areas like digital technology, AI, and cybersecurity.\n",
      "\n",
      "6. Diaspora Ties: The Indian diaspora in the US is significant and continues to grow, strengthening cultural and demographic ties.\n",
      "\n",
      "However, there are challenges such as India's resistance to align strictly with any global power, issues of human rights, difference in opinion about Iran, Russia and other global affairs.\n",
      "\n",
      "In conclusion, while it is tricky to predict the future, the above-mentioned factors will likely shape the future trajectory of Indo-US relations. The relationship has overall been on an upward trend, with increasing strategic and global cooperation, but it also faces a number of challenges.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4', api_key=api_key)\n",
    "\n",
    "### Agent Customization\n",
    "\n",
    "#- We can assign a role to our agent\n",
    "#- help in fitting agent to specific use case\n",
    "# This will help us in multi agent frameworks later\n",
    "\n",
    "asssistant = AssistantAgent(\n",
    "    name = 'politicalscience_expert',\n",
    "    model_client=model_client,\n",
    "    description='A knowledgeable assistant with expertise in political science',\n",
    "    system_message='You are a political science expert with deep knowledge of world politics. Provide detailed and accuragte answers about political events,figures and timelines and explanation'\n",
    ")\n",
    "\n",
    "async def test_politicalscience_expert():\n",
    "    result = await asssistant.run(task = 'What is the future of India and US relationship?')\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_politicalscience_expert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1efc60",
   "metadata": {},
   "source": [
    "# Using tools for MS Autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2ebef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Toronto is cloudy with a high of -5 degree celsius.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4', api_key=api_key)\n",
    "\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather for a given city.\n",
    "    This is a placeholder function and should be replaced with actual weather fetching logic.\n",
    "    For example, you could use a weather API to get real-time data.\n",
    "    :param city: Name of the city to fetch weather for.\n",
    "    :return: Weather information as a string.\n",
    "    \"\"\"\n",
    "    # Placeholder function to simulate weather fetching\n",
    "    return f\"The weather in {city} is cloudy with a high of -5 degree celsius.\"\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name = 'weather_assistant',\n",
    "    model_client=model_client,\n",
    "    system_message='You are a weather assistant, Use the right tool when asked about the weather in a city.',\n",
    "    tools= [get_weather]\n",
    ")\n",
    "\n",
    "async def test_weather_tool():\n",
    "    result = await assistant.run(task = 'What is the weather in Toronto?')\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_weather_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0f87b",
   "metadata": {},
   "source": [
    "# Messages in Autogen\n",
    "-  We can imagine messages as the way agent communicate each other - chatting with our Friend. \n",
    "\n",
    "- When we communicate with the agents -----> sending a message\n",
    "- when it responds ---> it too sends a message\n",
    "\n",
    "- TextMessage \n",
    "- ImageMessage\n",
    "- ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653c0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2023, the Prime Minister of India is Narendra Modi.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage,MultiModalMessage\n",
    "from autogen_core import Image as AGImage\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o',api_key=api_key)\n",
    "\n",
    "# Simple text message \n",
    "agent = AssistantAgent(\n",
    "    name = \"text_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message='You are a helpful assistant. answer question accurately'\n",
    ")\n",
    "\n",
    "async def test_text_messages():\n",
    "    text_msg = TextMessage(content = 'Who is prime minister of India?', source='user')\n",
    "    result = await agent.run(task=text_msg)\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "await test_text_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fff448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a pair of white high-heeled shoes against a red, splattered background.\n"
     ]
    }
   ],
   "source": [
    "async def test_multi_modal():\n",
    "\n",
    "    response = requests.get('https://picsum.photos/id/21/200/300') # 23 for the image of folks\n",
    "    pil_image = Image.open(BytesIO(response.content))\n",
    "    ag_image = AGImage(pil_image)\n",
    "\n",
    "    multi_modal_msg = MultiModalMessage(\n",
    "        content = ['What is in the image?',ag_image],\n",
    "        source='user'\n",
    "    )\n",
    "\n",
    "    result = await agent.run(task=multi_modal_msg)\n",
    "    print(result.messages[-1].content)\n",
    "\n",
    "\n",
    "await test_multi_modal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff89b4",
   "metadata": {},
   "source": [
    "# Mention about on_message() and on_messages_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb2e81",
   "metadata": {},
   "source": [
    "# Structured output via autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a96aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Mars\",\n",
      "  \"age\": 4500\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class PlanetInfo(BaseModel):\n",
    "    name: str\n",
    "    color: str\n",
    "    distance_miles: int\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model = 'gpt-4o',\n",
    "    api_key=api_key,\n",
    "    response_format=PlanetInfo\n",
    "    )\n",
    "\n",
    "unstructured_model_client = OpenAIChatCompletionClient(\n",
    "    model = 'gpt-4o',\n",
    "    api_key=api_key,\n",
    "    # response_format=PlanetInfo\n",
    "    )\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name='planet_agent',\n",
    "    model_client=unstructured_model_client,\n",
    "    system_message=\"You are a helpful assistant that provides information about planets. Return the output in the structure JSON\" \\\n",
    "    \"{ name :str\" \\\n",
    "    \"age : int\" \\\n",
    "    \"}\"\n",
    ")\n",
    "async def test_structured_output():\n",
    "    task = TextMessage(content = \"Please provide information about Mars.\",source='User')\n",
    "    result = await agent.run(task=task)\n",
    "    structured_response = result.messages[-1].content\n",
    "    print(structured_response)\n",
    "\n",
    "await test_structured_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e324efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Mars\",\"color\":\"Red\",\"distance_miles\":142000000}\n"
     ]
    }
   ],
   "source": [
    "agent = AssistantAgent(\n",
    "    name='planet_agent',\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant that provides information about planets.\"\n",
    ")\n",
    "async def test_structured_output():\n",
    "    task = TextMessage(content = \"Please provide information about Mars.\",source='User')\n",
    "    result = await agent.run(task=task)\n",
    "    structured_response = result.messages[-1].content\n",
    "    print(structured_response)\n",
    "\n",
    "await test_structured_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c26240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
